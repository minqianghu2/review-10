Review on “Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods”

This paper proposed multiple guidelines for by analyzing ten current vulnerabilities detecting method and evaluating  future proposed defenses. The authors studied how neural networks are applied to image classification, since it is the most accurate machine learning method by far. 

The authors evaluate the defenses under three different threat models,. They not only consider the generic attacks, that do not takes some specific and complex measures to stimulate specifc detectors, which makes the evaluation concrete and rigrorous, white box attacks which are used for breaking each defense when tailored given defences are also included.  

The author also analyze and finalize  the attach approaches in order to evaluate the robustness of each of the defenses. Some evaluations are “evaluate with a strong attack”, “perfoming an adaptive, white -box attack”. 

In addition, the authors also conclude a secondary classification based on the detection.

It is considerable that how attackers might react to any proposed defense, and to evaluate whether the defense remains secure against an attackers who know how it work.
